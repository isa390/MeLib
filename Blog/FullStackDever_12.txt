<br>2022-05-20 15:24:17: 整体上，可观测平台是一个需要实时处理巨量数据的（每分钟40T 输入数据，200亿个时序数据点写入）垂直领域实时数据平台。 而且，本身蚂蚁监控技术团队服务的上层业务就是公司的SRE与稳定性团队，因此可以 说是线上稳定性的最后一道保障，需要在各种极端情况下保证这个实时系统自身的稳定。 要在一套解决方案中同时做好实时性、稳定性、低成本这三个点，其基础技术挑战非常大。<br><br>2022-05-20 15:22:30: 蚂蚁的观测平台平时每分钟都在产生200亿个时序点上。如何提升极致的读写性能，甚至在双十一这样的业务峰值的时候，也能达到比较好的性能是一个重要的命题。而且，由于业务体量巨大，在解决吞吐问题的时候，也需要考虑资源成本（机器）。<br><br>2022-05-20 15:19:24:基于监控的数据和智能化能力快速实现自己的个性化需求，目前平台已经有3万个API持续为各种应用场景持续提供服务。<br><br>2022-05-18 11:32:06:kafka容量评估之网卡  1、网卡对比分析   通过上图分析可以得出 千兆网卡和万兆网卡的区别最大之处在于网口的传输速率的不同，千兆网卡的传输速率是1000Mbps，万兆网卡的则是10Gbps万兆网卡是千兆网卡传输速率的10倍。 性能上讲，万兆网卡的性能肯定比千兆网卡要好。万兆网卡现在主流的是10G的，发展趋势正逐步面向40G、100G网卡。但还是要根据使用环境和预算来选择投入，毕竟千兆网卡和万兆网卡的性价比区间还是挺大的。  2、网卡选择分析  根据 第一二步 分析结果，高峰期的时候，每秒会有大约 6万 请求涌入，即每台机器 约1万 请求涌入 (60000 / 7)， 每秒要接收的数据大小为: 10000 * 20 kb = 184 M/s， 外加上数据副本的同步网络请求，总共需要 184 * 3 = 552 M/s。   一般情况下，网卡带宽是不会达到上限的，对于千兆网卡，我们能用的基本在700M左右， 通过上面计算结果，千兆网卡基本可以满足，万兆网卡更好。  3、场景总结  要搞定 10亿+ 请求，需要 7台物理机， 每台物理机内存选择 128G内存 为主，需要 16个cpu core(32个性能更好)，千兆网卡基本可以满足，万兆网卡更好。<br><br>2022-05-18 11:30:17:kafka容量评估之CPU压力  1、CPU Core分析  我们评估需要多少个 CPU Core，主要是看 Kafka 进程里会有多少个线程， 线程主要是依托多核CPU来执行的，如果线程特别多，但是 CPU核很少，就会导致CPU负载很高，会导致整体工作线程执行的效率不高,性能也不会好。 所以我们要保证CPU Core的充足，来保障系统的稳定性和性能最优。  2、Kafka 网络架构及线程数计算   我们评估下 Kafka 服务器启动后会有多少线程在跑，其实这部分内容跟kafka超高并发网络架构密切相关， 上图是Kafka 超高并发网络架构图， 从图中我们可以分析得出：   除了上图所列的还有其他一些线程，所以估算下来，一个 kafka 服务启动后，会 有100多个线程在跑。   2、场景总结  要搞定 10亿+ 请求，需要 7台物理机， 每台物理机内存选择 128G内存 为主，需要 16个cpu core(32个性能更好)。<br><br>2022-05-18 11:28:15:kafka容量评估之内存  1、Kafka 写磁盘流程及内存分析   从上图可以得出 Kafka 读写数据的流程主要都是基于os cache，所以基本上 Kafka 都是基于内存来进行数据流转的，这样的话要 分配尽可能多的内存资源给os cache。  kafka的核心源码基本都是用 scala 和 java (客户端)写的，底层都是基于 JVM 来运行的，所以要分配一定的内存给 JVM 以保证服务的稳定性。对于 Kafka 的设计，并没有把很多的数据结构存储到 JVM 中， 所以根据经验，给 JVM 分配6~10G就足够了。    从上图可以看出一个 Topic 会对于多个 partition，一个 partition 会对应多个 segment ，一个 segment 会对应磁盘上4个log文件。假设我们这个平台总共100个 Topic ，那么总共有 100 Topic * 5 partition * 3 副本 = 1500 partition 。 对于 partition 来说实际上就是物理机上一个文件目录， .log就是存储数据文件的，默认情况下一个 .log日志文件大小为1G。  如果要保证这1500个 partition 的最新的 .log 文件的数据都在内存中，这样性能当然是最好的，需要 1500  * 1G = 1500 G 内存，但是我们没有必要所有的数据都驻留到内存中，我们只保证 25%左右 的数据在内存中就可以了，这样大概需要 1500 * 250M = 1500 * 0.25G = 375G内存， 通过 第二步 分析结果，我们总共需要 7台物理机， 这样的话 每台服务器只需要约54G内存，外加上面分析的JVM的10G，总共需要64G内存。 还要保留一部分内存给操作系统使用，故我们选择 128G内存的服务器 是非常够用了。  2、场景总结  要搞定 10亿+ 请求，需要 7台物理机， 每台物理机内存选择 128G内存 为主，这样内存会比较充裕。<br><br>2022-05-18 11:24:23:kafka容量评估之磁盘  1、机械硬盘 OR 固态硬盘SSD  两者主要区别如下：  SSD就是固态硬盘，它的优点是速度快，日常的读写比机械硬盘快几十倍上百倍。缺点是单位成本高，不适合做大容量存储。  HDD就是机械硬盘，它的优点是单位成本低，适合做大容量存储，但速度远不如SSD。  首先SSD硬盘性能好，主要是指的随机读写能力性能好，非常适合Mysql这样的集群，而 SSD的顺序读写性能跟机械硬盘的性能是差不多的。  Kafka 写磁盘是顺序追加写的， 所以对于 kafka 集群来说，我们使用 普通机械硬盘 就可以了。  2、每台服务器需要多少块硬盘  根据 第一二步骤 计算结果，我们需要 7台物理机， 一共需要存储 162T 数据，大约每台机器需要存储 23T 数据，根据以往经验一般服务器配置 11块 硬盘，这样每块硬盘大约存储2T的数据就可以了，另外为了服务器性能和稳定性，我们一般要保留一部分空间，保守按每块硬盘 最大能存储3T数据。  3、场景总结  要搞定 10亿+ 请求，需要 7台物理机， 使用 普通机械硬盘 进行存储，每台服务器 11块 硬盘，每块硬盘存储 2T 数据。<br><br>2022-05-18 11:20:52:、物理机 OR 虚拟机  一般对于Kafka，Mysql，Hadoop 等集群自建的时候，都会使用物理机来进行搭建，性能和稳定性相对虚拟机要强很多。  2、物理机数量计算  在 第一步 中我们分析得出 系统高峰期 的时候要支撑 6万QPS， 如果公司资金和资源充足的情况下，我们一般会让高峰期的QPS控制在集群总承载QPS能力的 30%左右， 这样的话可以得出集群能承载的 总QPS能力约为20万左右， 这样系统才会是安全的。  3、场景总结  根据经验可以得出 每台物理机支撑4万QPS 是没有问题的，从QPS角度分析，我们要支撑 10亿+ 请求，大约需要 5台物理机， 考虑到消费者请求，需要增加约1.5倍机器，即 7台物理机<br><br>2022-05-18 11:16:34:kafka容量评估需求场景分析  1、集群如何每天hold住10亿+请求  拿电商平台为例，kafka 集群每天需要承载10亿+请求流量数据，一天24小时，对于平台来说，晚上12点到凌晨8点这8个小时几乎没多少数据涌入的。这里我们使用 「二八法则」 来进行预估，也就是80%的数据（8亿）会在剩余的16个小时涌入，且8亿中的80%的数据（约6.4亿）会在这16个小时的20%时间 （约3小时）涌入。  通过上面的场景分析，可以得出如下：  QPS计算公式 = 640000000 ÷ (3 * 60 * 60) = 6万， 也就是说高峰期集群需要扛住每秒6万的并发请求。  假设 每条数据平均按20kb(生产端有数据汇总) 来算, 那就是 1000000000 * 20kb = 18T， 一般情况下我们都会设置 3个副本， 即 54T， 另外 kafka 数据是有保留时间周期的,  一般情况是保留 最近3天的数据， 即 54T * 3 = 162T。  2、场景总结  要搞定 10亿+ 请求，高峰期要支撑 6万QPS， 需要大约 162T 的存储空间。<br>